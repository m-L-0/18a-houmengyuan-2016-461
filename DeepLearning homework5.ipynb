{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.欠完备自编码器\n",
    "(1)实现欠完备自编码器\n",
    "(2)修改不同大小的隐藏层，观察自编码器的输出表现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.降噪自编码器\n",
    "实现降噪自编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0 111372.87\n",
      "1 93316.76\n",
      "2 88167.766\n",
      "3 81623.95\n",
      "4 79598.55\n",
      "5 74131.31\n",
      "6 73553.86\n",
      "7 73230.06\n",
      "8 70209.11\n",
      "9 69576.88\n",
      "10 67659.31\n",
      "11 67723.125\n",
      "12 65237.91\n",
      "13 65427.918\n",
      "14 65031.75\n",
      "15 64403.055\n",
      "16 63778.234\n",
      "17 63997.44\n",
      "18 63401.535\n",
      "19 62778.453\n",
      "20 62671.27\n",
      "21 62785.492\n",
      "22 62226.426\n",
      "23 61226.83\n",
      "24 62245.402\n",
      "25 61097.504\n",
      "26 61392.45\n",
      "27 61229.617\n",
      "28 60494.234\n",
      "29 59681.383\n",
      "30 60667.562\n",
      "31 61433.957\n",
      "32 60017.777\n",
      "33 60476.96\n",
      "34 59946.547\n",
      "35 59718.58\n",
      "36 59597.188\n",
      "37 59615.527\n",
      "38 60335.84\n",
      "39 58954.855\n",
      "40 59370.734\n",
      "41 59155.145\n",
      "42 59554.46\n",
      "43 58441.566\n",
      "44 59221.79\n",
      "45 58429.645\n",
      "46 58665.375\n",
      "47 59069.312\n",
      "48 58185.844\n",
      "49 57904.79\n",
      "50 58258.188\n",
      "51 58115.79\n",
      "52 59674.266\n",
      "53 58402.195\n",
      "54 58305.133\n",
      "55 58259.223\n",
      "56 58049.055\n",
      "57 58160.523\n",
      "58 57455.008\n",
      "59 57728.297\n",
      "60 57480.09\n",
      "61 57525.875\n",
      "62 57513.402\n",
      "63 58009.688\n",
      "64 58136.43\n",
      "65 57003.9\n",
      "66 58087.438\n",
      "67 57468.836\n",
      "68 56985.12\n",
      "69 57547.145\n",
      "70 57350.27\n",
      "71 57734.195\n",
      "72 57556.742\n",
      "73 57501.82\n",
      "74 57135.15\n",
      "75 56772.35\n",
      "76 58163.676\n",
      "77 57207.73\n",
      "78 56990.89\n",
      "79 56981.3\n",
      "80 57608.74\n",
      "81 57288.97\n",
      "82 56298.934\n",
      "83 56857.18\n",
      "84 57574.023\n",
      "85 56366.72\n",
      "86 56518.164\n",
      "87 56847.95\n",
      "88 56818.234\n",
      "89 56507.703\n",
      "90 56319.97\n",
      "91 56547.11\n",
      "92 56603.906\n",
      "93 56486.504\n",
      "94 57649.02\n",
      "95 56642.117\n",
      "96 56469.68\n",
      "97 56177.438\n",
      "98 56104.64\n",
      "99 56444.867\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_width = 28 \n",
    "n_visible = mnist_width * mnist_width \n",
    "n_hidden = 500 \n",
    "corruption_level = 0.3 \n",
    "# 输入的一张图片用28x28=784的向量表示. \n",
    "X = tf.placeholder(\"float\", [None, n_visible], name='X') \n",
    "# 用于将部分输入数据置为0 \n",
    "mask = tf.placeholder(\"float\", [None, n_visible], name='mask') \n",
    "# create nodes for hidden variables \n",
    "W_init_max = 4 * np.sqrt(6. / (n_visible + n_hidden)) \n",
    "W_init = tf.random_uniform(shape=[n_visible, n_hidden], \n",
    "                           minval=-W_init_max, \n",
    "                           maxval=W_init_max) \n",
    "# 编码器 \n",
    "W = tf.Variable(W_init, name='W')#shape:784x500 \n",
    "b = tf.Variable(tf.zeros([n_hidden]), name='b')#隐含层的偏置 \n",
    "#解码器 \n",
    "W_prime = tf.transpose(W) \n",
    "b_prime = tf.Variable(tf.zeros([n_visible]), name='b_prime') \n",
    "def model(X, mask, W, b, W_prime, b_prime): \n",
    "    tilde_X = mask * X # corrupted X \n",
    "    Y = tf.nn.sigmoid(tf.matmul(tilde_X, W) + b) # hidden state \n",
    "    Z = tf.nn.sigmoid(tf.matmul(Y, W_prime) + b_prime) # reconstructed input \n",
    "    return Z \n",
    "# build model graph \n",
    "Z = model(X, mask, W, b, W_prime, b_prime) \n",
    "# create cost function \n",
    "cost = tf.reduce_sum(tf.pow(X - Z, 2)) # minimize squared error \n",
    "train_op = tf.train.GradientDescentOptimizer(0.02).minimize(cost) # construct an optimizer \n",
    "# load MNIST data \n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True) \n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels \n",
    "# Launch the graph in a session \n",
    "with tf.Session() as sess: \n",
    "    # you need to initialize all variables \n",
    "    tf.initialize_all_variables().run() \n",
    "    for i in range(100): \n",
    "        for start, end in zip(range(0, len(trX), 128), range(128, len(trX)+1, 128)): \n",
    "            input_ = trX[start:end] \n",
    "            mask_np = np.random.binomial(1, 1 - corruption_level, input_.shape) \n",
    "            sess.run(train_op, feed_dict={X: input_, mask: mask_np})\n",
    "        mask_np = np.random.binomial(1, 1 - corruption_level, teX.shape) \n",
    "        print(i, sess.run(cost, feed_dict={X: teX, mask: mask_np}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.卷积自编码器\n",
    "(1)实现卷积自编码器\n",
    "(2)使用卷积自编码器对图片进行降噪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "inputs_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs=inputs_, filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, pool_size=(2,2), strides=(2,2), padding='same')\n",
    "# Now 14x14x32\n",
    "conv2 = tf.layers.conv2d(inputs=maxpool1, filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x32\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, pool_size=(2,2), strides=(2,2), padding='same')\n",
    "# Now 7x7x32\n",
    "conv3 = tf.layers.conv2d(inputs=maxpool2, filters=16, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "encoded = tf.layers.max_pooling2d(conv3, pool_size=(2,2), strides=(2,2), padding='same')\n",
    "# Now 4x4x16\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_images(encoded, size=(7,7), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# Now 7x7x16\n",
    "conv4 = tf.layers.conv2d(inputs=upsample1, filters=16, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "upsample2 = tf.image.resize_images(conv4, size=(14,14), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# Now 14x14x16\n",
    "conv5 = tf.layers.conv2d(inputs=upsample2, filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x32\n",
    "upsample3 = tf.image.resize_images(conv5, size=(28,28), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# Now 28x28x32\n",
    "conv6 = tf.layers.conv2d(inputs=upsample3, filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "logits = tf.layers.conv2d(inputs=conv6, filters=1, kernel_size=(3,3), padding='same', activation=None)\n",
    "#Now 28x28x1\n",
    "# Pass logits through sigmoid to get reconstructed image\n",
    "decoded = tf.nn.sigmoid(logits)\n",
    "# Pass logits through sigmoid and calculate the cross-entropy loss\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "# Get cost and define the optimizer\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Training loss: 0.6906\n",
      "Epoch: 1/100... Training loss: 0.6749\n",
      "Epoch: 1/100... Training loss: 0.6482\n",
      "Epoch: 1/100... Training loss: 0.6126\n",
      "Epoch: 1/100... Training loss: 0.5639\n",
      "Epoch: 1/100... Training loss: 0.5229\n",
      "Epoch: 1/100... Training loss: 0.5153\n",
      "Epoch: 1/100... Training loss: 0.5241\n",
      "Epoch: 1/100... Training loss: 0.5162\n",
      "Epoch: 1/100... Training loss: 0.5088\n",
      "Epoch: 1/100... Training loss: 0.4903\n",
      "Epoch: 1/100... Training loss: 0.4802\n",
      "Epoch: 1/100... Training loss: 0.4827\n",
      "Epoch: 1/100... Training loss: 0.4771\n",
      "Epoch: 1/100... Training loss: 0.4775\n",
      "Epoch: 1/100... Training loss: 0.4617\n",
      "Epoch: 1/100... Training loss: 0.4634\n",
      "Epoch: 1/100... Training loss: 0.4423\n",
      "Epoch: 1/100... Training loss: 0.4447\n",
      "Epoch: 1/100... Training loss: 0.4319\n",
      "Epoch: 1/100... Training loss: 0.4103\n",
      "Epoch: 1/100... Training loss: 0.3959\n",
      "Epoch: 1/100... Training loss: 0.3830\n",
      "Epoch: 1/100... Training loss: 0.3823\n",
      "Epoch: 1/100... Training loss: 0.3627\n",
      "Epoch: 1/100... Training loss: 0.3534\n",
      "Epoch: 1/100... Training loss: 0.3387\n",
      "Epoch: 1/100... Training loss: 0.3147\n",
      "Epoch: 1/100... Training loss: 0.3080\n",
      "Epoch: 1/100... Training loss: 0.2925\n",
      "Epoch: 1/100... Training loss: 0.2884\n",
      "Epoch: 1/100... Training loss: 0.2801\n",
      "Epoch: 1/100... Training loss: 0.2782\n",
      "Epoch: 1/100... Training loss: 0.2753\n",
      "Epoch: 1/100... Training loss: 0.2690\n",
      "Epoch: 1/100... Training loss: 0.2718\n",
      "Epoch: 1/100... Training loss: 0.2796\n",
      "Epoch: 1/100... Training loss: 0.2761\n",
      "Epoch: 1/100... Training loss: 0.2702\n",
      "Epoch: 1/100... Training loss: 0.2699\n",
      "Epoch: 1/100... Training loss: 0.2638\n",
      "Epoch: 1/100... Training loss: 0.2680\n",
      "Epoch: 1/100... Training loss: 0.2692\n",
      "Epoch: 1/100... Training loss: 0.2650\n",
      "Epoch: 1/100... Training loss: 0.2643\n",
      "Epoch: 1/100... Training loss: 0.2618\n",
      "Epoch: 1/100... Training loss: 0.2668\n",
      "Epoch: 1/100... Training loss: 0.2609\n",
      "Epoch: 1/100... Training loss: 0.2577\n",
      "Epoch: 1/100... Training loss: 0.2593\n",
      "Epoch: 1/100... Training loss: 0.2541\n",
      "Epoch: 1/100... Training loss: 0.2579\n",
      "Epoch: 1/100... Training loss: 0.2495\n",
      "Epoch: 1/100... Training loss: 0.2571\n",
      "Epoch: 1/100... Training loss: 0.2570\n",
      "Epoch: 1/100... Training loss: 0.2489\n",
      "Epoch: 1/100... Training loss: 0.2434\n",
      "Epoch: 1/100... Training loss: 0.2494\n",
      "Epoch: 1/100... Training loss: 0.2381\n",
      "Epoch: 1/100... Training loss: 0.2420\n",
      "Epoch: 1/100... Training loss: 0.2405\n",
      "Epoch: 1/100... Training loss: 0.2371\n",
      "Epoch: 1/100... Training loss: 0.2379\n",
      "Epoch: 1/100... Training loss: 0.2317\n",
      "Epoch: 1/100... Training loss: 0.2463\n",
      "Epoch: 1/100... Training loss: 0.2447\n",
      "Epoch: 1/100... Training loss: 0.2332\n",
      "Epoch: 1/100... Training loss: 0.2484\n",
      "Epoch: 1/100... Training loss: 0.2358\n",
      "Epoch: 1/100... Training loss: 0.2374\n",
      "Epoch: 1/100... Training loss: 0.2254\n",
      "Epoch: 1/100... Training loss: 0.2424\n",
      "Epoch: 1/100... Training loss: 0.2279\n",
      "Epoch: 1/100... Training loss: 0.2325\n",
      "Epoch: 1/100... Training loss: 0.2276\n",
      "Epoch: 1/100... Training loss: 0.2355\n",
      "Epoch: 1/100... Training loss: 0.2297\n",
      "Epoch: 1/100... Training loss: 0.2314\n",
      "Epoch: 1/100... Training loss: 0.2317\n",
      "Epoch: 1/100... Training loss: 0.2279\n",
      "Epoch: 1/100... Training loss: 0.2295\n",
      "Epoch: 1/100... Training loss: 0.2247\n",
      "Epoch: 1/100... Training loss: 0.2200\n",
      "Epoch: 1/100... Training loss: 0.2266\n",
      "Epoch: 1/100... Training loss: 0.2180\n",
      "Epoch: 1/100... Training loss: 0.2235\n",
      "Epoch: 1/100... Training loss: 0.2230\n",
      "Epoch: 1/100... Training loss: 0.2156\n",
      "Epoch: 1/100... Training loss: 0.2243\n",
      "Epoch: 1/100... Training loss: 0.2169\n",
      "Epoch: 1/100... Training loss: 0.2253\n",
      "Epoch: 1/100... Training loss: 0.2157\n",
      "Epoch: 1/100... Training loss: 0.2161\n",
      "Epoch: 1/100... Training loss: 0.2174\n",
      "Epoch: 1/100... Training loss: 0.2201\n",
      "Epoch: 1/100... Training loss: 0.2185\n",
      "Epoch: 1/100... Training loss: 0.2157\n",
      "Epoch: 1/100... Training loss: 0.2198\n",
      "Epoch: 1/100... Training loss: 0.2151\n",
      "Epoch: 1/100... Training loss: 0.2124\n",
      "Epoch: 1/100... Training loss: 0.2061\n",
      "Epoch: 1/100... Training loss: 0.2099\n",
      "Epoch: 1/100... Training loss: 0.2132\n",
      "Epoch: 1/100... Training loss: 0.2044\n",
      "Epoch: 1/100... Training loss: 0.2076\n",
      "Epoch: 1/100... Training loss: 0.2126\n",
      "Epoch: 1/100... Training loss: 0.2159\n",
      "Epoch: 1/100... Training loss: 0.2091\n",
      "Epoch: 1/100... Training loss: 0.2033\n",
      "Epoch: 1/100... Training loss: 0.2033\n",
      "Epoch: 1/100... Training loss: 0.2054\n",
      "Epoch: 1/100... Training loss: 0.2079\n",
      "Epoch: 1/100... Training loss: 0.2114\n",
      "Epoch: 1/100... Training loss: 0.2091\n",
      "Epoch: 1/100... Training loss: 0.2069\n",
      "Epoch: 1/100... Training loss: 0.2042\n",
      "Epoch: 1/100... Training loss: 0.2028\n",
      "Epoch: 1/100... Training loss: 0.2053\n",
      "Epoch: 1/100... Training loss: 0.2019\n",
      "Epoch: 1/100... Training loss: 0.2033\n",
      "Epoch: 1/100... Training loss: 0.2017\n",
      "Epoch: 1/100... Training loss: 0.2065\n",
      "Epoch: 1/100... Training loss: 0.2034\n",
      "Epoch: 1/100... Training loss: 0.2002\n",
      "Epoch: 1/100... Training loss: 0.2046\n",
      "Epoch: 1/100... Training loss: 0.1979\n",
      "Epoch: 1/100... Training loss: 0.1996\n",
      "Epoch: 1/100... Training loss: 0.2011\n",
      "Epoch: 1/100... Training loss: 0.1966\n",
      "Epoch: 1/100... Training loss: 0.2002\n",
      "Epoch: 1/100... Training loss: 0.1998\n",
      "Epoch: 1/100... Training loss: 0.1982\n",
      "Epoch: 1/100... Training loss: 0.1957\n",
      "Epoch: 1/100... Training loss: 0.1976\n",
      "Epoch: 1/100... Training loss: 0.1957\n",
      "Epoch: 1/100... Training loss: 0.1952\n",
      "Epoch: 1/100... Training loss: 0.1969\n",
      "Epoch: 1/100... Training loss: 0.1992\n",
      "Epoch: 1/100... Training loss: 0.1941\n",
      "Epoch: 1/100... Training loss: 0.1942\n",
      "Epoch: 1/100... Training loss: 0.1905\n",
      "Epoch: 1/100... Training loss: 0.1931\n",
      "Epoch: 1/100... Training loss: 0.2000\n",
      "Epoch: 1/100... Training loss: 0.1942\n",
      "Epoch: 1/100... Training loss: 0.1991\n",
      "Epoch: 1/100... Training loss: 0.1948\n",
      "Epoch: 1/100... Training loss: 0.1877\n",
      "Epoch: 1/100... Training loss: 0.1913\n",
      "Epoch: 1/100... Training loss: 0.1884\n",
      "Epoch: 1/100... Training loss: 0.1862\n",
      "Epoch: 1/100... Training loss: 0.1846\n",
      "Epoch: 1/100... Training loss: 0.1911\n",
      "Epoch: 1/100... Training loss: 0.1893\n",
      "Epoch: 1/100... Training loss: 0.1919\n",
      "Epoch: 1/100... Training loss: 0.1888\n",
      "Epoch: 1/100... Training loss: 0.1880\n",
      "Epoch: 1/100... Training loss: 0.1887\n",
      "Epoch: 1/100... Training loss: 0.1894\n",
      "Epoch: 1/100... Training loss: 0.1883\n",
      "Epoch: 1/100... Training loss: 0.1899\n",
      "Epoch: 1/100... Training loss: 0.1882\n",
      "Epoch: 1/100... Training loss: 0.1874\n",
      "Epoch: 1/100... Training loss: 0.1856\n",
      "Epoch: 1/100... Training loss: 0.1839\n",
      "Epoch: 1/100... Training loss: 0.1856\n",
      "Epoch: 1/100... Training loss: 0.1850\n",
      "Epoch: 1/100... Training loss: 0.1852\n",
      "Epoch: 1/100... Training loss: 0.1862\n",
      "Epoch: 1/100... Training loss: 0.1802\n",
      "Epoch: 1/100... Training loss: 0.1834\n",
      "Epoch: 1/100... Training loss: 0.1836\n",
      "Epoch: 1/100... Training loss: 0.1872\n",
      "Epoch: 1/100... Training loss: 0.1868\n",
      "Epoch: 1/100... Training loss: 0.1869\n",
      "Epoch: 1/100... Training loss: 0.1897\n",
      "Epoch: 1/100... Training loss: 0.1819\n",
      "Epoch: 1/100... Training loss: 0.1836\n",
      "Epoch: 1/100... Training loss: 0.1800\n",
      "Epoch: 1/100... Training loss: 0.1833\n",
      "Epoch: 1/100... Training loss: 0.1910\n",
      "Epoch: 1/100... Training loss: 0.1846\n",
      "Epoch: 1/100... Training loss: 0.1796\n",
      "Epoch: 1/100... Training loss: 0.1881\n",
      "Epoch: 1/100... Training loss: 0.1865\n",
      "Epoch: 1/100... Training loss: 0.1833\n",
      "Epoch: 1/100... Training loss: 0.1825\n",
      "Epoch: 1/100... Training loss: 0.1855\n",
      "Epoch: 1/100... Training loss: 0.1816\n",
      "Epoch: 1/100... Training loss: 0.1876\n",
      "Epoch: 1/100... Training loss: 0.1890\n",
      "Epoch: 1/100... Training loss: 0.1767\n",
      "Epoch: 1/100... Training loss: 0.1851\n",
      "Epoch: 1/100... Training loss: 0.1867\n",
      "Epoch: 1/100... Training loss: 0.1832\n",
      "Epoch: 1/100... Training loss: 0.1820\n",
      "Epoch: 1/100... Training loss: 0.1809\n",
      "Epoch: 1/100... Training loss: 0.1845\n",
      "Epoch: 1/100... Training loss: 0.1810\n",
      "Epoch: 1/100... Training loss: 0.1836\n",
      "Epoch: 1/100... Training loss: 0.1786\n",
      "Epoch: 1/100... Training loss: 0.1875\n",
      "Epoch: 1/100... Training loss: 0.1822\n",
      "Epoch: 1/100... Training loss: 0.1835\n",
      "Epoch: 1/100... Training loss: 0.1793\n",
      "Epoch: 1/100... Training loss: 0.1825\n",
      "Epoch: 1/100... Training loss: 0.1866\n",
      "Epoch: 1/100... Training loss: 0.1761\n",
      "Epoch: 1/100... Training loss: 0.1773\n",
      "Epoch: 1/100... Training loss: 0.1802\n",
      "Epoch: 1/100... Training loss: 0.1785\n",
      "Epoch: 1/100... Training loss: 0.1743\n",
      "Epoch: 1/100... Training loss: 0.1807\n",
      "Epoch: 1/100... Training loss: 0.1738\n",
      "Epoch: 1/100... Training loss: 0.1804\n",
      "Epoch: 1/100... Training loss: 0.1762\n",
      "Epoch: 1/100... Training loss: 0.1823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Training loss: 0.1807\n",
      "Epoch: 1/100... Training loss: 0.1774\n",
      "Epoch: 1/100... Training loss: 0.1802\n",
      "Epoch: 1/100... Training loss: 0.1772\n",
      "Epoch: 1/100... Training loss: 0.1762\n",
      "Epoch: 1/100... Training loss: 0.1824\n",
      "Epoch: 1/100... Training loss: 0.1783\n",
      "Epoch: 1/100... Training loss: 0.1778\n",
      "Epoch: 1/100... Training loss: 0.1780\n",
      "Epoch: 1/100... Training loss: 0.1741\n",
      "Epoch: 1/100... Training loss: 0.1731\n",
      "Epoch: 1/100... Training loss: 0.1762\n",
      "Epoch: 1/100... Training loss: 0.1758\n",
      "Epoch: 1/100... Training loss: 0.1784\n",
      "Epoch: 1/100... Training loss: 0.1773\n",
      "Epoch: 1/100... Training loss: 0.1792\n",
      "Epoch: 1/100... Training loss: 0.1825\n",
      "Epoch: 1/100... Training loss: 0.1772\n",
      "Epoch: 1/100... Training loss: 0.1797\n",
      "Epoch: 1/100... Training loss: 0.1771\n",
      "Epoch: 1/100... Training loss: 0.1731\n",
      "Epoch: 1/100... Training loss: 0.1679\n",
      "Epoch: 1/100... Training loss: 0.1774\n",
      "Epoch: 1/100... Training loss: 0.1722\n",
      "Epoch: 1/100... Training loss: 0.1743\n",
      "Epoch: 1/100... Training loss: 0.1773\n",
      "Epoch: 1/100... Training loss: 0.1739\n",
      "Epoch: 1/100... Training loss: 0.1782\n",
      "Epoch: 1/100... Training loss: 0.1763\n",
      "Epoch: 1/100... Training loss: 0.1753\n",
      "Epoch: 1/100... Training loss: 0.1723\n",
      "Epoch: 1/100... Training loss: 0.1796\n",
      "Epoch: 1/100... Training loss: 0.1784\n",
      "Epoch: 1/100... Training loss: 0.1705\n",
      "Epoch: 1/100... Training loss: 0.1708\n",
      "Epoch: 1/100... Training loss: 0.1747\n",
      "Epoch: 1/100... Training loss: 0.1729\n",
      "Epoch: 1/100... Training loss: 0.1708\n",
      "Epoch: 1/100... Training loss: 0.1702\n",
      "Epoch: 1/100... Training loss: 0.1764\n",
      "Epoch: 1/100... Training loss: 0.1748\n",
      "Epoch: 1/100... Training loss: 0.1723\n",
      "Epoch: 1/100... Training loss: 0.1731\n",
      "Epoch: 1/100... Training loss: 0.1715\n",
      "Epoch: 1/100... Training loss: 0.1743\n",
      "Epoch: 1/100... Training loss: 0.1714\n",
      "Epoch: 1/100... Training loss: 0.1741\n",
      "Epoch: 1/100... Training loss: 0.1773\n",
      "Epoch: 1/100... Training loss: 0.1729\n",
      "Epoch: 1/100... Training loss: 0.1676\n",
      "Epoch: 1/100... Training loss: 0.1728\n",
      "Epoch: 1/100... Training loss: 0.1715\n",
      "Epoch: 1/100... Training loss: 0.1683\n",
      "Epoch: 1/100... Training loss: 0.1718\n",
      "Epoch: 1/100... Training loss: 0.1699\n",
      "Epoch: 1/100... Training loss: 0.1692\n",
      "Epoch: 1/100... Training loss: 0.1701\n",
      "Epoch: 1/100... Training loss: 0.1705\n",
      "Epoch: 1/100... Training loss: 0.1631\n",
      "Epoch: 2/100... Training loss: 0.1700\n",
      "Epoch: 2/100... Training loss: 0.1692\n",
      "Epoch: 2/100... Training loss: 0.1770\n",
      "Epoch: 2/100... Training loss: 0.1675\n",
      "Epoch: 2/100... Training loss: 0.1670\n",
      "Epoch: 2/100... Training loss: 0.1701\n",
      "Epoch: 2/100... Training loss: 0.1684\n",
      "Epoch: 2/100... Training loss: 0.1720\n",
      "Epoch: 2/100... Training loss: 0.1643\n",
      "Epoch: 2/100... Training loss: 0.1728\n",
      "Epoch: 2/100... Training loss: 0.1684\n",
      "Epoch: 2/100... Training loss: 0.1658\n",
      "Epoch: 2/100... Training loss: 0.1701\n",
      "Epoch: 2/100... Training loss: 0.1743\n",
      "Epoch: 2/100... Training loss: 0.1681\n",
      "Epoch: 2/100... Training loss: 0.1687\n",
      "Epoch: 2/100... Training loss: 0.1628\n",
      "Epoch: 2/100... Training loss: 0.1644\n",
      "Epoch: 2/100... Training loss: 0.1665\n",
      "Epoch: 2/100... Training loss: 0.1732\n",
      "Epoch: 2/100... Training loss: 0.1710\n",
      "Epoch: 2/100... Training loss: 0.1648\n",
      "Epoch: 2/100... Training loss: 0.1652\n",
      "Epoch: 2/100... Training loss: 0.1609\n",
      "Epoch: 2/100... Training loss: 0.1706\n",
      "Epoch: 2/100... Training loss: 0.1701\n",
      "Epoch: 2/100... Training loss: 0.1640\n",
      "Epoch: 2/100... Training loss: 0.1708\n",
      "Epoch: 2/100... Training loss: 0.1710\n",
      "Epoch: 2/100... Training loss: 0.1664\n",
      "Epoch: 2/100... Training loss: 0.1671\n",
      "Epoch: 2/100... Training loss: 0.1633\n",
      "Epoch: 2/100... Training loss: 0.1684\n",
      "Epoch: 2/100... Training loss: 0.1692\n",
      "Epoch: 2/100... Training loss: 0.1664\n",
      "Epoch: 2/100... Training loss: 0.1716\n",
      "Epoch: 2/100... Training loss: 0.1615\n",
      "Epoch: 2/100... Training loss: 0.1667\n",
      "Epoch: 2/100... Training loss: 0.1698\n",
      "Epoch: 2/100... Training loss: 0.1642\n",
      "Epoch: 2/100... Training loss: 0.1722\n",
      "Epoch: 2/100... Training loss: 0.1665\n",
      "Epoch: 2/100... Training loss: 0.1650\n",
      "Epoch: 2/100... Training loss: 0.1622\n",
      "Epoch: 2/100... Training loss: 0.1649\n",
      "Epoch: 2/100... Training loss: 0.1632\n",
      "Epoch: 2/100... Training loss: 0.1674\n",
      "Epoch: 2/100... Training loss: 0.1626\n",
      "Epoch: 2/100... Training loss: 0.1636\n",
      "Epoch: 2/100... Training loss: 0.1642\n",
      "Epoch: 2/100... Training loss: 0.1599\n",
      "Epoch: 2/100... Training loss: 0.1690\n",
      "Epoch: 2/100... Training loss: 0.1651\n",
      "Epoch: 2/100... Training loss: 0.1642\n",
      "Epoch: 2/100... Training loss: 0.1633\n",
      "Epoch: 2/100... Training loss: 0.1684\n",
      "Epoch: 2/100... Training loss: 0.1659\n",
      "Epoch: 2/100... Training loss: 0.1612\n",
      "Epoch: 2/100... Training loss: 0.1601\n",
      "Epoch: 2/100... Training loss: 0.1624\n",
      "Epoch: 2/100... Training loss: 0.1629\n",
      "Epoch: 2/100... Training loss: 0.1614\n",
      "Epoch: 2/100... Training loss: 0.1607\n",
      "Epoch: 2/100... Training loss: 0.1599\n",
      "Epoch: 2/100... Training loss: 0.1608\n",
      "Epoch: 2/100... Training loss: 0.1668\n",
      "Epoch: 2/100... Training loss: 0.1616\n",
      "Epoch: 2/100... Training loss: 0.1568\n",
      "Epoch: 2/100... Training loss: 0.1654\n",
      "Epoch: 2/100... Training loss: 0.1610\n",
      "Epoch: 2/100... Training loss: 0.1588\n",
      "Epoch: 2/100... Training loss: 0.1591\n",
      "Epoch: 2/100... Training loss: 0.1618\n",
      "Epoch: 2/100... Training loss: 0.1668\n",
      "Epoch: 2/100... Training loss: 0.1703\n",
      "Epoch: 2/100... Training loss: 0.1599\n",
      "Epoch: 2/100... Training loss: 0.1603\n",
      "Epoch: 2/100... Training loss: 0.1595\n",
      "Epoch: 2/100... Training loss: 0.1633\n",
      "Epoch: 2/100... Training loss: 0.1605\n",
      "Epoch: 2/100... Training loss: 0.1547\n",
      "Epoch: 2/100... Training loss: 0.1631\n",
      "Epoch: 2/100... Training loss: 0.1620\n",
      "Epoch: 2/100... Training loss: 0.1542\n",
      "Epoch: 2/100... Training loss: 0.1587\n",
      "Epoch: 2/100... Training loss: 0.1617\n",
      "Epoch: 2/100... Training loss: 0.1623\n",
      "Epoch: 2/100... Training loss: 0.1620\n",
      "Epoch: 2/100... Training loss: 0.1640\n",
      "Epoch: 2/100... Training loss: 0.1549\n",
      "Epoch: 2/100... Training loss: 0.1587\n",
      "Epoch: 2/100... Training loss: 0.1642\n",
      "Epoch: 2/100... Training loss: 0.1624\n",
      "Epoch: 2/100... Training loss: 0.1618\n",
      "Epoch: 2/100... Training loss: 0.1601\n",
      "Epoch: 2/100... Training loss: 0.1629\n",
      "Epoch: 2/100... Training loss: 0.1608\n",
      "Epoch: 2/100... Training loss: 0.1618\n",
      "Epoch: 2/100... Training loss: 0.1651\n",
      "Epoch: 2/100... Training loss: 0.1578\n",
      "Epoch: 2/100... Training loss: 0.1556\n",
      "Epoch: 2/100... Training loss: 0.1613\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1608\n",
      "Epoch: 2/100... Training loss: 0.1572\n",
      "Epoch: 2/100... Training loss: 0.1602\n",
      "Epoch: 2/100... Training loss: 0.1604\n",
      "Epoch: 2/100... Training loss: 0.1559\n",
      "Epoch: 2/100... Training loss: 0.1574\n",
      "Epoch: 2/100... Training loss: 0.1606\n",
      "Epoch: 2/100... Training loss: 0.1579\n",
      "Epoch: 2/100... Training loss: 0.1526\n",
      "Epoch: 2/100... Training loss: 0.1561\n",
      "Epoch: 2/100... Training loss: 0.1572\n",
      "Epoch: 2/100... Training loss: 0.1642\n",
      "Epoch: 2/100... Training loss: 0.1520\n",
      "Epoch: 2/100... Training loss: 0.1589\n",
      "Epoch: 2/100... Training loss: 0.1588\n",
      "Epoch: 2/100... Training loss: 0.1549\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1531\n",
      "Epoch: 2/100... Training loss: 0.1543\n",
      "Epoch: 2/100... Training loss: 0.1543\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1562\n",
      "Epoch: 2/100... Training loss: 0.1549\n",
      "Epoch: 2/100... Training loss: 0.1517\n",
      "Epoch: 2/100... Training loss: 0.1524\n",
      "Epoch: 2/100... Training loss: 0.1620\n",
      "Epoch: 2/100... Training loss: 0.1607\n",
      "Epoch: 2/100... Training loss: 0.1507\n",
      "Epoch: 2/100... Training loss: 0.1616\n",
      "Epoch: 2/100... Training loss: 0.1540\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1490\n",
      "Epoch: 2/100... Training loss: 0.1580\n",
      "Epoch: 2/100... Training loss: 0.1530\n",
      "Epoch: 2/100... Training loss: 0.1583\n",
      "Epoch: 2/100... Training loss: 0.1543\n",
      "Epoch: 2/100... Training loss: 0.1586\n",
      "Epoch: 2/100... Training loss: 0.1493\n",
      "Epoch: 2/100... Training loss: 0.1527\n",
      "Epoch: 2/100... Training loss: 0.1546\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1452\n",
      "Epoch: 2/100... Training loss: 0.1547\n",
      "Epoch: 2/100... Training loss: 0.1609\n",
      "Epoch: 2/100... Training loss: 0.1541\n",
      "Epoch: 2/100... Training loss: 0.1559\n",
      "Epoch: 2/100... Training loss: 0.1532\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1531\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1624\n",
      "Epoch: 2/100... Training loss: 0.1535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100... Training loss: 0.1598\n",
      "Epoch: 2/100... Training loss: 0.1601\n",
      "Epoch: 2/100... Training loss: 0.1548\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1590\n",
      "Epoch: 2/100... Training loss: 0.1559\n",
      "Epoch: 2/100... Training loss: 0.1556\n",
      "Epoch: 2/100... Training loss: 0.1596\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1542\n",
      "Epoch: 2/100... Training loss: 0.1556\n",
      "Epoch: 2/100... Training loss: 0.1525\n",
      "Epoch: 2/100... Training loss: 0.1517\n",
      "Epoch: 2/100... Training loss: 0.1538\n",
      "Epoch: 2/100... Training loss: 0.1552\n",
      "Epoch: 2/100... Training loss: 0.1576\n",
      "Epoch: 2/100... Training loss: 0.1480\n",
      "Epoch: 2/100... Training loss: 0.1604\n",
      "Epoch: 2/100... Training loss: 0.1527\n",
      "Epoch: 2/100... Training loss: 0.1488\n",
      "Epoch: 2/100... Training loss: 0.1552\n",
      "Epoch: 2/100... Training loss: 0.1533\n",
      "Epoch: 2/100... Training loss: 0.1599\n",
      "Epoch: 2/100... Training loss: 0.1582\n",
      "Epoch: 2/100... Training loss: 0.1551\n",
      "Epoch: 2/100... Training loss: 0.1528\n",
      "Epoch: 2/100... Training loss: 0.1477\n",
      "Epoch: 2/100... Training loss: 0.1536\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1511\n",
      "Epoch: 2/100... Training loss: 0.1525\n",
      "Epoch: 2/100... Training loss: 0.1571\n",
      "Epoch: 2/100... Training loss: 0.1523\n",
      "Epoch: 2/100... Training loss: 0.1540\n",
      "Epoch: 2/100... Training loss: 0.1516\n",
      "Epoch: 2/100... Training loss: 0.1545\n",
      "Epoch: 2/100... Training loss: 0.1546\n",
      "Epoch: 2/100... Training loss: 0.1601\n",
      "Epoch: 2/100... Training loss: 0.1507\n",
      "Epoch: 2/100... Training loss: 0.1566\n",
      "Epoch: 2/100... Training loss: 0.1492\n",
      "Epoch: 2/100... Training loss: 0.1543\n",
      "Epoch: 2/100... Training loss: 0.1553\n",
      "Epoch: 2/100... Training loss: 0.1489\n",
      "Epoch: 2/100... Training loss: 0.1544\n",
      "Epoch: 2/100... Training loss: 0.1582\n",
      "Epoch: 2/100... Training loss: 0.1525\n",
      "Epoch: 2/100... Training loss: 0.1503\n",
      "Epoch: 2/100... Training loss: 0.1479\n",
      "Epoch: 2/100... Training loss: 0.1491\n",
      "Epoch: 2/100... Training loss: 0.1459\n",
      "Epoch: 2/100... Training loss: 0.1517\n",
      "Epoch: 2/100... Training loss: 0.1520\n",
      "Epoch: 2/100... Training loss: 0.1456\n",
      "Epoch: 2/100... Training loss: 0.1492\n",
      "Epoch: 2/100... Training loss: 0.1486\n",
      "Epoch: 2/100... Training loss: 0.1549\n",
      "Epoch: 2/100... Training loss: 0.1534\n",
      "Epoch: 2/100... Training loss: 0.1439\n",
      "Epoch: 2/100... Training loss: 0.1502\n",
      "Epoch: 2/100... Training loss: 0.1455\n",
      "Epoch: 2/100... Training loss: 0.1551\n",
      "Epoch: 2/100... Training loss: 0.1506\n",
      "Epoch: 2/100... Training loss: 0.1499\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1502\n",
      "Epoch: 2/100... Training loss: 0.1495\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1578\n",
      "Epoch: 2/100... Training loss: 0.1519\n",
      "Epoch: 2/100... Training loss: 0.1471\n",
      "Epoch: 2/100... Training loss: 0.1514\n",
      "Epoch: 2/100... Training loss: 0.1488\n",
      "Epoch: 2/100... Training loss: 0.1469\n",
      "Epoch: 2/100... Training loss: 0.1520\n",
      "Epoch: 2/100... Training loss: 0.1489\n",
      "Epoch: 2/100... Training loss: 0.1545\n",
      "Epoch: 2/100... Training loss: 0.1520\n",
      "Epoch: 2/100... Training loss: 0.1463\n",
      "Epoch: 2/100... Training loss: 0.1504\n",
      "Epoch: 2/100... Training loss: 0.1512\n",
      "Epoch: 2/100... Training loss: 0.1480\n",
      "Epoch: 2/100... Training loss: 0.1490\n",
      "Epoch: 2/100... Training loss: 0.1552\n",
      "Epoch: 2/100... Training loss: 0.1487\n",
      "Epoch: 2/100... Training loss: 0.1512\n",
      "Epoch: 2/100... Training loss: 0.1453\n",
      "Epoch: 2/100... Training loss: 0.1478\n",
      "Epoch: 2/100... Training loss: 0.1525\n",
      "Epoch: 2/100... Training loss: 0.1508\n",
      "Epoch: 2/100... Training loss: 0.1546\n",
      "Epoch: 2/100... Training loss: 0.1489\n",
      "Epoch: 2/100... Training loss: 0.1477\n",
      "Epoch: 2/100... Training loss: 0.1519\n",
      "Epoch: 2/100... Training loss: 0.1456\n",
      "Epoch: 2/100... Training loss: 0.1477\n",
      "Epoch: 2/100... Training loss: 0.1549\n",
      "Epoch: 2/100... Training loss: 0.1495\n",
      "Epoch: 2/100... Training loss: 0.1455\n",
      "Epoch: 2/100... Training loss: 0.1469\n",
      "Epoch: 2/100... Training loss: 0.1500\n",
      "Epoch: 2/100... Training loss: 0.1494\n",
      "Epoch: 2/100... Training loss: 0.1510\n",
      "Epoch: 2/100... Training loss: 0.1485\n",
      "Epoch: 2/100... Training loss: 0.1487\n",
      "Epoch: 2/100... Training loss: 0.1465\n",
      "Epoch: 2/100... Training loss: 0.1476\n",
      "Epoch: 2/100... Training loss: 0.1480\n",
      "Epoch: 2/100... Training loss: 0.1438\n",
      "Epoch: 2/100... Training loss: 0.1468\n",
      "Epoch: 2/100... Training loss: 0.1373\n",
      "Epoch: 2/100... Training loss: 0.1494\n",
      "Epoch: 2/100... Training loss: 0.1484\n",
      "Epoch: 2/100... Training loss: 0.1432\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1467\n",
      "Epoch: 3/100... Training loss: 0.1509\n",
      "Epoch: 3/100... Training loss: 0.1468\n",
      "Epoch: 3/100... Training loss: 0.1412\n",
      "Epoch: 3/100... Training loss: 0.1435\n",
      "Epoch: 3/100... Training loss: 0.1504\n",
      "Epoch: 3/100... Training loss: 0.1447\n",
      "Epoch: 3/100... Training loss: 0.1432\n",
      "Epoch: 3/100... Training loss: 0.1419\n",
      "Epoch: 3/100... Training loss: 0.1504\n",
      "Epoch: 3/100... Training loss: 0.1518\n",
      "Epoch: 3/100... Training loss: 0.1463\n",
      "Epoch: 3/100... Training loss: 0.1443\n",
      "Epoch: 3/100... Training loss: 0.1507\n",
      "Epoch: 3/100... Training loss: 0.1441\n",
      "Epoch: 3/100... Training loss: 0.1483\n",
      "Epoch: 3/100... Training loss: 0.1465\n",
      "Epoch: 3/100... Training loss: 0.1461\n",
      "Epoch: 3/100... Training loss: 0.1481\n",
      "Epoch: 3/100... Training loss: 0.1470\n",
      "Epoch: 3/100... Training loss: 0.1528\n",
      "Epoch: 3/100... Training loss: 0.1508\n",
      "Epoch: 3/100... Training loss: 0.1440\n",
      "Epoch: 3/100... Training loss: 0.1438\n",
      "Epoch: 3/100... Training loss: 0.1433\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1471\n",
      "Epoch: 3/100... Training loss: 0.1468\n",
      "Epoch: 3/100... Training loss: 0.1470\n",
      "Epoch: 3/100... Training loss: 0.1430\n",
      "Epoch: 3/100... Training loss: 0.1468\n",
      "Epoch: 3/100... Training loss: 0.1426\n",
      "Epoch: 3/100... Training loss: 0.1432\n",
      "Epoch: 3/100... Training loss: 0.1429\n",
      "Epoch: 3/100... Training loss: 0.1420\n",
      "Epoch: 3/100... Training loss: 0.1434\n",
      "Epoch: 3/100... Training loss: 0.1438\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1466\n",
      "Epoch: 3/100... Training loss: 0.1473\n",
      "Epoch: 3/100... Training loss: 0.1459\n",
      "Epoch: 3/100... Training loss: 0.1434\n",
      "Epoch: 3/100... Training loss: 0.1432\n",
      "Epoch: 3/100... Training loss: 0.1432\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1393\n",
      "Epoch: 3/100... Training loss: 0.1439\n",
      "Epoch: 3/100... Training loss: 0.1473\n",
      "Epoch: 3/100... Training loss: 0.1477\n",
      "Epoch: 3/100... Training loss: 0.1513\n",
      "Epoch: 3/100... Training loss: 0.1441\n",
      "Epoch: 3/100... Training loss: 0.1435\n",
      "Epoch: 3/100... Training loss: 0.1494\n",
      "Epoch: 3/100... Training loss: 0.1470\n",
      "Epoch: 3/100... Training loss: 0.1508\n",
      "Epoch: 3/100... Training loss: 0.1414\n",
      "Epoch: 3/100... Training loss: 0.1448\n",
      "Epoch: 3/100... Training loss: 0.1412\n",
      "Epoch: 3/100... Training loss: 0.1419\n",
      "Epoch: 3/100... Training loss: 0.1432\n",
      "Epoch: 3/100... Training loss: 0.1424\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1451\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1457\n",
      "Epoch: 3/100... Training loss: 0.1439\n",
      "Epoch: 3/100... Training loss: 0.1481\n",
      "Epoch: 3/100... Training loss: 0.1480\n",
      "Epoch: 3/100... Training loss: 0.1490\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1478\n",
      "Epoch: 3/100... Training loss: 0.1451\n",
      "Epoch: 3/100... Training loss: 0.1457\n",
      "Epoch: 3/100... Training loss: 0.1436\n",
      "Epoch: 3/100... Training loss: 0.1462\n",
      "Epoch: 3/100... Training loss: 0.1440\n",
      "Epoch: 3/100... Training loss: 0.1457\n",
      "Epoch: 3/100... Training loss: 0.1479\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1440\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1447\n",
      "Epoch: 3/100... Training loss: 0.1447\n",
      "Epoch: 3/100... Training loss: 0.1431\n",
      "Epoch: 3/100... Training loss: 0.1469\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1470\n",
      "Epoch: 3/100... Training loss: 0.1453\n",
      "Epoch: 3/100... Training loss: 0.1439\n",
      "Epoch: 3/100... Training loss: 0.1414\n",
      "Epoch: 3/100... Training loss: 0.1419\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1420\n",
      "Epoch: 3/100... Training loss: 0.1448\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1410\n",
      "Epoch: 3/100... Training loss: 0.1402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100... Training loss: 0.1394\n",
      "Epoch: 3/100... Training loss: 0.1341\n",
      "Epoch: 3/100... Training loss: 0.1383\n",
      "Epoch: 3/100... Training loss: 0.1441\n",
      "Epoch: 3/100... Training loss: 0.1388\n",
      "Epoch: 3/100... Training loss: 0.1420\n",
      "Epoch: 3/100... Training loss: 0.1424\n",
      "Epoch: 3/100... Training loss: 0.1403\n",
      "Epoch: 3/100... Training loss: 0.1449\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1434\n",
      "Epoch: 3/100... Training loss: 0.1454\n",
      "Epoch: 3/100... Training loss: 0.1444\n",
      "Epoch: 3/100... Training loss: 0.1394\n",
      "Epoch: 3/100... Training loss: 0.1467\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1382\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1376\n",
      "Epoch: 3/100... Training loss: 0.1398\n",
      "Epoch: 3/100... Training loss: 0.1411\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1410\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1427\n",
      "Epoch: 3/100... Training loss: 0.1440\n",
      "Epoch: 3/100... Training loss: 0.1401\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1374\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1424\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1371\n",
      "Epoch: 3/100... Training loss: 0.1414\n",
      "Epoch: 3/100... Training loss: 0.1394\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1422\n",
      "Epoch: 3/100... Training loss: 0.1460\n",
      "Epoch: 3/100... Training loss: 0.1398\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1431\n",
      "Epoch: 3/100... Training loss: 0.1402\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1421\n",
      "Epoch: 3/100... Training loss: 0.1414\n",
      "Epoch: 3/100... Training loss: 0.1373\n",
      "Epoch: 3/100... Training loss: 0.1430\n",
      "Epoch: 3/100... Training loss: 0.1423\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1382\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1415\n",
      "Epoch: 3/100... Training loss: 0.1362\n",
      "Epoch: 3/100... Training loss: 0.1424\n",
      "Epoch: 3/100... Training loss: 0.1400\n",
      "Epoch: 3/100... Training loss: 0.1446\n",
      "Epoch: 3/100... Training loss: 0.1463\n",
      "Epoch: 3/100... Training loss: 0.1448\n",
      "Epoch: 3/100... Training loss: 0.1375\n",
      "Epoch: 3/100... Training loss: 0.1460\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1402\n",
      "Epoch: 3/100... Training loss: 0.1408\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1398\n",
      "Epoch: 3/100... Training loss: 0.1360\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1466\n",
      "Epoch: 3/100... Training loss: 0.1337\n",
      "Epoch: 3/100... Training loss: 0.1438\n",
      "Epoch: 3/100... Training loss: 0.1377\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1354\n",
      "Epoch: 3/100... Training loss: 0.1391\n",
      "Epoch: 3/100... Training loss: 0.1423\n",
      "Epoch: 3/100... Training loss: 0.1449\n",
      "Epoch: 3/100... Training loss: 0.1398\n",
      "Epoch: 3/100... Training loss: 0.1414\n",
      "Epoch: 3/100... Training loss: 0.1377\n",
      "Epoch: 3/100... Training loss: 0.1402\n",
      "Epoch: 3/100... Training loss: 0.1373\n",
      "Epoch: 3/100... Training loss: 0.1395\n",
      "Epoch: 3/100... Training loss: 0.1360\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1419\n",
      "Epoch: 3/100... Training loss: 0.1425\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1355\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1373\n",
      "Epoch: 3/100... Training loss: 0.1408\n",
      "Epoch: 3/100... Training loss: 0.1446\n",
      "Epoch: 3/100... Training loss: 0.1427\n",
      "Epoch: 3/100... Training loss: 0.1370\n",
      "Epoch: 3/100... Training loss: 0.1444\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1419\n",
      "Epoch: 3/100... Training loss: 0.1407\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1433\n",
      "Epoch: 3/100... Training loss: 0.1373\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1376\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1302\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1395\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1322\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1382\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1384\n",
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1385\n",
      "Epoch: 3/100... Training loss: 0.1419\n",
      "Epoch: 3/100... Training loss: 0.1368\n",
      "Epoch: 3/100... Training loss: 0.1361\n",
      "Epoch: 3/100... Training loss: 0.1385\n",
      "Epoch: 3/100... Training loss: 0.1318\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1324\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1399\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1412\n",
      "Epoch: 3/100... Training loss: 0.1362\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1316\n",
      "Epoch: 3/100... Training loss: 0.1370\n",
      "Epoch: 3/100... Training loss: 0.1376\n",
      "Epoch: 3/100... Training loss: 0.1370\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1407\n",
      "Epoch: 3/100... Training loss: 0.1370\n",
      "Epoch: 3/100... Training loss: 0.1342\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1363\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1339\n",
      "Epoch: 3/100... Training loss: 0.1395\n",
      "Epoch: 3/100... Training loss: 0.1355\n",
      "Epoch: 3/100... Training loss: 0.1330\n",
      "Epoch: 3/100... Training loss: 0.1337\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1300\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1321\n",
      "Epoch: 3/100... Training loss: 0.1412\n",
      "Epoch: 3/100... Training loss: 0.1334\n",
      "Epoch: 3/100... Training loss: 0.1345\n",
      "Epoch: 4/100... Training loss: 0.1372\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1347\n",
      "Epoch: 4/100... Training loss: 0.1372\n",
      "Epoch: 4/100... Training loss: 0.1386\n",
      "Epoch: 4/100... Training loss: 0.1305\n",
      "Epoch: 4/100... Training loss: 0.1339\n",
      "Epoch: 4/100... Training loss: 0.1357\n",
      "Epoch: 4/100... Training loss: 0.1362\n",
      "Epoch: 4/100... Training loss: 0.1337\n",
      "Epoch: 4/100... Training loss: 0.1370\n",
      "Epoch: 4/100... Training loss: 0.1346\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1409\n",
      "Epoch: 4/100... Training loss: 0.1312\n",
      "Epoch: 4/100... Training loss: 0.1406\n",
      "Epoch: 4/100... Training loss: 0.1355\n",
      "Epoch: 4/100... Training loss: 0.1357\n",
      "Epoch: 4/100... Training loss: 0.1389\n",
      "Epoch: 4/100... Training loss: 0.1339\n",
      "Epoch: 4/100... Training loss: 0.1372\n",
      "Epoch: 4/100... Training loss: 0.1336\n",
      "Epoch: 4/100... Training loss: 0.1368\n",
      "Epoch: 4/100... Training loss: 0.1359\n",
      "Epoch: 4/100... Training loss: 0.1382\n",
      "Epoch: 4/100... Training loss: 0.1338\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1347\n",
      "Epoch: 4/100... Training loss: 0.1301\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1370\n",
      "Epoch: 4/100... Training loss: 0.1355\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1312\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1350\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100... Training loss: 0.1312\n",
      "Epoch: 4/100... Training loss: 0.1326\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1358\n",
      "Epoch: 4/100... Training loss: 0.1351\n",
      "Epoch: 4/100... Training loss: 0.1366\n",
      "Epoch: 4/100... Training loss: 0.1386\n",
      "Epoch: 4/100... Training loss: 0.1318\n",
      "Epoch: 4/100... Training loss: 0.1382\n",
      "Epoch: 4/100... Training loss: 0.1402\n",
      "Epoch: 4/100... Training loss: 0.1343\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1392\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1385\n",
      "Epoch: 4/100... Training loss: 0.1328\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1365\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1335\n",
      "Epoch: 4/100... Training loss: 0.1347\n",
      "Epoch: 4/100... Training loss: 0.1355\n",
      "Epoch: 4/100... Training loss: 0.1364\n",
      "Epoch: 4/100... Training loss: 0.1359\n",
      "Epoch: 4/100... Training loss: 0.1400\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1352\n",
      "Epoch: 4/100... Training loss: 0.1328\n",
      "Epoch: 4/100... Training loss: 0.1301\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1409\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1313\n",
      "Epoch: 4/100... Training loss: 0.1282\n",
      "Epoch: 4/100... Training loss: 0.1335\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1371\n",
      "Epoch: 4/100... Training loss: 0.1338\n",
      "Epoch: 4/100... Training loss: 0.1351\n",
      "Epoch: 4/100... Training loss: 0.1341\n",
      "Epoch: 4/100... Training loss: 0.1354\n",
      "Epoch: 4/100... Training loss: 0.1338\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1366\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1339\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1377\n",
      "Epoch: 4/100... Training loss: 0.1359\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1352\n",
      "Epoch: 4/100... Training loss: 0.1357\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1371\n",
      "Epoch: 4/100... Training loss: 0.1349\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1382\n",
      "Epoch: 4/100... Training loss: 0.1339\n",
      "Epoch: 4/100... Training loss: 0.1357\n",
      "Epoch: 4/100... Training loss: 0.1343\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1341\n",
      "Epoch: 4/100... Training loss: 0.1341\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1323\n",
      "Epoch: 4/100... Training loss: 0.1400\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1347\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1345\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1338\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1367\n",
      "Epoch: 4/100... Training loss: 0.1339\n",
      "Epoch: 4/100... Training loss: 0.1373\n",
      "Epoch: 4/100... Training loss: 0.1356\n",
      "Epoch: 4/100... Training loss: 0.1336\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1341\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1383\n",
      "Epoch: 4/100... Training loss: 0.1352\n",
      "Epoch: 4/100... Training loss: 0.1337\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1361\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1347\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1342\n",
      "Epoch: 4/100... Training loss: 0.1357\n",
      "Epoch: 4/100... Training loss: 0.1365\n",
      "Epoch: 4/100... Training loss: 0.1339\n",
      "Epoch: 4/100... Training loss: 0.1323\n",
      "Epoch: 4/100... Training loss: 0.1350\n",
      "Epoch: 4/100... Training loss: 0.1378\n",
      "Epoch: 4/100... Training loss: 0.1326\n",
      "Epoch: 4/100... Training loss: 0.1335\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1335\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1317\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1311\n",
      "Epoch: 4/100... Training loss: 0.1385\n",
      "Epoch: 4/100... Training loss: 0.1349\n",
      "Epoch: 4/100... Training loss: 0.1301\n",
      "Epoch: 4/100... Training loss: 0.1311\n",
      "Epoch: 4/100... Training loss: 0.1349\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1324\n",
      "Epoch: 4/100... Training loss: 0.1313\n",
      "Epoch: 4/100... Training loss: 0.1341\n",
      "Epoch: 4/100... Training loss: 0.1346\n",
      "Epoch: 4/100... Training loss: 0.1313\n",
      "Epoch: 4/100... Training loss: 0.1371\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1310\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1346\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1346\n",
      "Epoch: 4/100... Training loss: 0.1335\n",
      "Epoch: 4/100... Training loss: 0.1326\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1307\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1276\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1281\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1283\n",
      "Epoch: 4/100... Training loss: 0.1318\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1275\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1349\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1338\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1285\n",
      "Epoch: 4/100... Training loss: 0.1312\n",
      "Epoch: 4/100... Training loss: 0.1355\n",
      "Epoch: 4/100... Training loss: 0.1343\n",
      "Epoch: 4/100... Training loss: 0.1305\n",
      "Epoch: 4/100... Training loss: 0.1362\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1346\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1331\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1362\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1336\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1305\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1278\n",
      "Epoch: 4/100... Training loss: 0.1355\n",
      "Epoch: 4/100... Training loss: 0.1312\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1337\n",
      "Epoch: 4/100... Training loss: 0.1348\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1348\n",
      "Epoch: 4/100... Training loss: 0.1240\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1313\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1341\n",
      "Epoch: 4/100... Training loss: 0.1307\n",
      "Epoch: 4/100... Training loss: 0.1352\n",
      "Epoch: 4/100... Training loss: 0.1280\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1340\n",
      "Epoch: 4/100... Training loss: 0.1320\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1350\n",
      "Epoch: 4/100... Training loss: 0.1312\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1326\n",
      "Epoch: 4/100... Training loss: 0.1340\n",
      "Epoch: 4/100... Training loss: 0.1293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1318\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1279\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1318\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1277\n",
      "Epoch: 4/100... Training loss: 0.1354\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1362\n",
      "Epoch: 4/100... Training loss: 0.1319\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1336\n",
      "Epoch: 4/100... Training loss: 0.1362\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 5/100... Training loss: 0.1379\n",
      "Epoch: 5/100... Training loss: 0.1334\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1378\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1341\n",
      "Epoch: 5/100... Training loss: 0.1314\n",
      "Epoch: 5/100... Training loss: 0.1326\n",
      "Epoch: 5/100... Training loss: 0.1329\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1318\n",
      "Epoch: 5/100... Training loss: 0.1323\n",
      "Epoch: 5/100... Training loss: 0.1304\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1319\n",
      "Epoch: 5/100... Training loss: 0.1296\n",
      "Epoch: 5/100... Training loss: 0.1303\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1298\n",
      "Epoch: 5/100... Training loss: 0.1216\n",
      "Epoch: 5/100... Training loss: 0.1304\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1302\n",
      "Epoch: 5/100... Training loss: 0.1300\n",
      "Epoch: 5/100... Training loss: 0.1296\n",
      "Epoch: 5/100... Training loss: 0.1320\n",
      "Epoch: 5/100... Training loss: 0.1310\n",
      "Epoch: 5/100... Training loss: 0.1296\n",
      "Epoch: 5/100... Training loss: 0.1300\n",
      "Epoch: 5/100... Training loss: 0.1293\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1284\n",
      "Epoch: 5/100... Training loss: 0.1318\n",
      "Epoch: 5/100... Training loss: 0.1318\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1299\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1249\n",
      "Epoch: 5/100... Training loss: 0.1348\n",
      "Epoch: 5/100... Training loss: 0.1308\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1301\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1274\n",
      "Epoch: 5/100... Training loss: 0.1301\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1288\n",
      "Epoch: 5/100... Training loss: 0.1292\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1346\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1296\n",
      "Epoch: 5/100... Training loss: 0.1307\n",
      "Epoch: 5/100... Training loss: 0.1295\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1311\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1270\n",
      "Epoch: 5/100... Training loss: 0.1325\n",
      "Epoch: 5/100... Training loss: 0.1286\n",
      "Epoch: 5/100... Training loss: 0.1288\n",
      "Epoch: 5/100... Training loss: 0.1322\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1304\n",
      "Epoch: 5/100... Training loss: 0.1292\n",
      "Epoch: 5/100... Training loss: 0.1299\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1307\n",
      "Epoch: 5/100... Training loss: 0.1322\n",
      "Epoch: 5/100... Training loss: 0.1289\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1311\n",
      "Epoch: 5/100... Training loss: 0.1299\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1287\n",
      "Epoch: 5/100... Training loss: 0.1288\n",
      "Epoch: 5/100... Training loss: 0.1318\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1314\n",
      "Epoch: 5/100... Training loss: 0.1312\n",
      "Epoch: 5/100... Training loss: 0.1284\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1318\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1296\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1364\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1281\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1327\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1214\n",
      "Epoch: 5/100... Training loss: 0.1301\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1312\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1295\n",
      "Epoch: 5/100... Training loss: 0.1337\n",
      "Epoch: 5/100... Training loss: 0.1293\n",
      "Epoch: 5/100... Training loss: 0.1311\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1295\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1289\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1221\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1324\n",
      "Epoch: 5/100... Training loss: 0.1261\n",
      "Epoch: 5/100... Training loss: 0.1248\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1316\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1296\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1296\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1307\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1300\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1281\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1288\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1293\n",
      "Epoch: 5/100... Training loss: 0.1281\n",
      "Epoch: 5/100... Training loss: 0.1343\n",
      "Epoch: 5/100... Training loss: 0.1288\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1281\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1295\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1292\n",
      "Epoch: 5/100... Training loss: 0.1300\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1286\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1244\n",
      "Epoch: 5/100... Training loss: 0.1309\n",
      "Epoch: 5/100... Training loss: 0.1270\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1311\n",
      "Epoch: 5/100... Training loss: 0.1313\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1311\n",
      "Epoch: 5/100... Training loss: 0.1295\n",
      "Epoch: 5/100... Training loss: 0.1310\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1295\n",
      "Epoch: 5/100... Training loss: 0.1295\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1292\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1297\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1249\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1290\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100... Training loss: 0.1295\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1303\n",
      "Epoch: 5/100... Training loss: 0.1289\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1288\n",
      "Epoch: 5/100... Training loss: 0.1314\n",
      "Epoch: 5/100... Training loss: 0.1281\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1284\n",
      "Epoch: 5/100... Training loss: 0.1309\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1308\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1232\n",
      "Epoch: 5/100... Training loss: 0.1303\n",
      "Epoch: 5/100... Training loss: 0.1319\n",
      "Epoch: 5/100... Training loss: 0.1296\n",
      "Epoch: 5/100... Training loss: 0.1281\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1311\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1336\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1231\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1284\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1290\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1222\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1284\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1309\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1302\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1249\n",
      "Epoch: 5/100... Training loss: 0.1305\n",
      "Epoch: 5/100... Training loss: 0.1319\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1213\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1286\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1231\n",
      "Epoch: 5/100... Training loss: 0.1308\n",
      "Epoch: 5/100... Training loss: 0.1285\n",
      "Epoch: 5/100... Training loss: 0.1288\n",
      "Epoch: 6/100... Training loss: 0.1250\n",
      "Epoch: 6/100... Training loss: 0.1283\n",
      "Epoch: 6/100... Training loss: 0.1269\n",
      "Epoch: 6/100... Training loss: 0.1289\n",
      "Epoch: 6/100... Training loss: 0.1250\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1241\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1271\n",
      "Epoch: 6/100... Training loss: 0.1271\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1282\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1275\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1268\n",
      "Epoch: 6/100... Training loss: 0.1283\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1280\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1257\n",
      "Epoch: 6/100... Training loss: 0.1303\n",
      "Epoch: 6/100... Training loss: 0.1292\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1288\n",
      "Epoch: 6/100... Training loss: 0.1231\n",
      "Epoch: 6/100... Training loss: 0.1277\n",
      "Epoch: 6/100... Training loss: 0.1286\n",
      "Epoch: 6/100... Training loss: 0.1312\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1286\n",
      "Epoch: 6/100... Training loss: 0.1278\n",
      "Epoch: 6/100... Training loss: 0.1285\n",
      "Epoch: 6/100... Training loss: 0.1271\n",
      "Epoch: 6/100... Training loss: 0.1292\n",
      "Epoch: 6/100... Training loss: 0.1307\n",
      "Epoch: 6/100... Training loss: 0.1298\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1246\n",
      "Epoch: 6/100... Training loss: 0.1270\n",
      "Epoch: 6/100... Training loss: 0.1280\n",
      "Epoch: 6/100... Training loss: 0.1280\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1285\n",
      "Epoch: 6/100... Training loss: 0.1277\n",
      "Epoch: 6/100... Training loss: 0.1263\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1257\n",
      "Epoch: 6/100... Training loss: 0.1261\n",
      "Epoch: 6/100... Training loss: 0.1285\n",
      "Epoch: 6/100... Training loss: 0.1246\n",
      "Epoch: 6/100... Training loss: 0.1256\n",
      "Epoch: 6/100... Training loss: 0.1301\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1267\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1274\n",
      "Epoch: 6/100... Training loss: 0.1274\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1251\n",
      "Epoch: 6/100... Training loss: 0.1254\n",
      "Epoch: 6/100... Training loss: 0.1290\n",
      "Epoch: 6/100... Training loss: 0.1247\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1289\n",
      "Epoch: 6/100... Training loss: 0.1259\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1256\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1266\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1250\n",
      "Epoch: 6/100... Training loss: 0.1278\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1288\n",
      "Epoch: 6/100... Training loss: 0.1261\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1258\n",
      "Epoch: 6/100... Training loss: 0.1277\n",
      "Epoch: 6/100... Training loss: 0.1258\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1285\n",
      "Epoch: 6/100... Training loss: 0.1257\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1268\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1258\n",
      "Epoch: 6/100... Training loss: 0.1271\n",
      "Epoch: 6/100... Training loss: 0.1250\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1202\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1280\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1246\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1225\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1273\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1250\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1241\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1260\n",
      "Epoch: 6/100... Training loss: 0.1247\n",
      "Epoch: 6/100... Training loss: 0.1210\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1269\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1267\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1266\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1263\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1260\n",
      "Epoch: 6/100... Training loss: 0.1276\n",
      "Epoch: 6/100... Training loss: 0.1256\n",
      "Epoch: 6/100... Training loss: 0.1301\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1269\n",
      "Epoch: 6/100... Training loss: 0.1282\n",
      "Epoch: 6/100... Training loss: 0.1283\n",
      "Epoch: 6/100... Training loss: 0.1270\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1225\n",
      "Epoch: 6/100... Training loss: 0.1247\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1266\n",
      "Epoch: 6/100... Training loss: 0.1276\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1254\n",
      "Epoch: 6/100... Training loss: 0.1280\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1257\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1256\n",
      "Epoch: 6/100... Training loss: 0.1292\n",
      "Epoch: 6/100... Training loss: 0.1282\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1312\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1258\n",
      "Epoch: 6/100... Training loss: 0.1289\n",
      "Epoch: 6/100... Training loss: 0.1270\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1289\n",
      "Epoch: 6/100... Training loss: 0.1203\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1263\n",
      "Epoch: 6/100... Training loss: 0.1275\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1245\n",
      "Epoch: 6/100... Training loss: 0.1213\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1259\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 6/100... Training loss: 0.1280\n",
      "Epoch: 6/100... Training loss: 0.1259\n",
      "Epoch: 6/100... Training loss: 0.1279\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1280\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1267\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1254\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1245\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1198\n",
      "Epoch: 6/100... Training loss: 0.1271\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1273\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1269\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1190\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1251\n",
      "Epoch: 6/100... Training loss: 0.1289\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1250\n",
      "Epoch: 6/100... Training loss: 0.1293\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1259\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1231\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1287\n",
      "Epoch: 6/100... Training loss: 0.1190\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1274\n",
      "Epoch: 6/100... Training loss: 0.1241\n",
      "Epoch: 6/100... Training loss: 0.1300\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1197\n",
      "Epoch: 6/100... Training loss: 0.1258\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1226\n",
      "Epoch: 7/100... Training loss: 0.1240\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1237\n",
      "Epoch: 7/100... Training loss: 0.1272\n",
      "Epoch: 7/100... Training loss: 0.1260\n",
      "Epoch: 7/100... Training loss: 0.1249\n",
      "Epoch: 7/100... Training loss: 0.1243\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1240\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1230\n",
      "Epoch: 7/100... Training loss: 0.1245\n",
      "Epoch: 7/100... Training loss: 0.1238\n",
      "Epoch: 7/100... Training loss: 0.1231\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1260\n",
      "Epoch: 7/100... Training loss: 0.1252\n",
      "Epoch: 7/100... Training loss: 0.1229\n",
      "Epoch: 7/100... Training loss: 0.1229\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1286\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1230\n",
      "Epoch: 7/100... Training loss: 0.1162\n",
      "Epoch: 7/100... Training loss: 0.1236\n",
      "Epoch: 7/100... Training loss: 0.1256\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1246\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1254\n",
      "Epoch: 7/100... Training loss: 0.1246\n",
      "Epoch: 7/100... Training loss: 0.1282\n",
      "Epoch: 7/100... Training loss: 0.1245\n",
      "Epoch: 7/100... Training loss: 0.1261\n",
      "Epoch: 7/100... Training loss: 0.1240\n",
      "Epoch: 7/100... Training loss: 0.1230\n",
      "Epoch: 7/100... Training loss: 0.1271\n",
      "Epoch: 7/100... Training loss: 0.1239\n",
      "Epoch: 7/100... Training loss: 0.1230\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1237\n",
      "Epoch: 7/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1265\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1240\n",
      "Epoch: 7/100... Training loss: 0.1254\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1242\n",
      "Epoch: 7/100... Training loss: 0.1238\n",
      "Epoch: 7/100... Training loss: 0.1214\n",
      "Epoch: 7/100... Training loss: 0.1261\n",
      "Epoch: 7/100... Training loss: 0.1229\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1271\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1279\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1252\n",
      "Epoch: 7/100... Training loss: 0.1247\n",
      "Epoch: 7/100... Training loss: 0.1166\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1250\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1245\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100... Training loss: 0.1242\n",
      "Epoch: 7/100... Training loss: 0.1214\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1219\n",
      "Epoch: 7/100... Training loss: 0.1269\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1256\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1253\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1262\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1264\n",
      "Epoch: 7/100... Training loss: 0.1256\n",
      "Epoch: 7/100... Training loss: 0.1230\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1249\n",
      "Epoch: 7/100... Training loss: 0.1226\n",
      "Epoch: 7/100... Training loss: 0.1263\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1269\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1237\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1258\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1260\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1244\n",
      "Epoch: 7/100... Training loss: 0.1242\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1231\n",
      "Epoch: 7/100... Training loss: 0.1214\n",
      "Epoch: 7/100... Training loss: 0.1231\n",
      "Epoch: 7/100... Training loss: 0.1241\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1233\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1258\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1230\n",
      "Epoch: 7/100... Training loss: 0.1231\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1240\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1241\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1266\n",
      "Epoch: 7/100... Training loss: 0.1253\n",
      "Epoch: 7/100... Training loss: 0.1255\n",
      "Epoch: 7/100... Training loss: 0.1251\n",
      "Epoch: 7/100... Training loss: 0.1237\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1261\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1275\n",
      "Epoch: 7/100... Training loss: 0.1219\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1219\n",
      "Epoch: 7/100... Training loss: 0.1239\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1240\n",
      "Epoch: 7/100... Training loss: 0.1304\n",
      "Epoch: 7/100... Training loss: 0.1137\n",
      "Epoch: 7/100... Training loss: 0.1265\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1219\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1219\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1263\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1231\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1248\n",
      "Epoch: 7/100... Training loss: 0.1260\n",
      "Epoch: 7/100... Training loss: 0.1239\n",
      "Epoch: 7/100... Training loss: 0.1223\n",
      "Epoch: 7/100... Training loss: 0.1237\n",
      "Epoch: 7/100... Training loss: 0.1245\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1250\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1238\n",
      "Epoch: 7/100... Training loss: 0.1229\n",
      "Epoch: 7/100... Training loss: 0.1223\n",
      "Epoch: 7/100... Training loss: 0.1219\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1239\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1257\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1248\n",
      "Epoch: 7/100... Training loss: 0.1226\n",
      "Epoch: 7/100... Training loss: 0.1214\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1278\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1214\n",
      "Epoch: 7/100... Training loss: 0.1218\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1249\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1233\n",
      "Epoch: 7/100... Training loss: 0.1238\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1219\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1163\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1249\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1214\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1256\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1167\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1164\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1184\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1206\n",
      "Epoch: 8/100... Training loss: 0.1229\n",
      "Epoch: 8/100... Training loss: 0.1259\n",
      "Epoch: 8/100... Training loss: 0.1222\n",
      "Epoch: 8/100... Training loss: 0.1221\n",
      "Epoch: 8/100... Training loss: 0.1214\n",
      "Epoch: 8/100... Training loss: 0.1242\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1216\n",
      "Epoch: 8/100... Training loss: 0.1247\n",
      "Epoch: 8/100... Training loss: 0.1238\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1229\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1234\n",
      "Epoch: 8/100... Training loss: 0.1219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1222\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1159\n",
      "Epoch: 8/100... Training loss: 0.1214\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1229\n",
      "Epoch: 8/100... Training loss: 0.1219\n",
      "Epoch: 8/100... Training loss: 0.1225\n",
      "Epoch: 8/100... Training loss: 0.1248\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1218\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1227\n",
      "Epoch: 8/100... Training loss: 0.1260\n",
      "Epoch: 8/100... Training loss: 0.1253\n",
      "Epoch: 8/100... Training loss: 0.1210\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1231\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1183\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1222\n",
      "Epoch: 8/100... Training loss: 0.1209\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1183\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1229\n",
      "Epoch: 8/100... Training loss: 0.1207\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1252\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1228\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1257\n",
      "Epoch: 8/100... Training loss: 0.1220\n",
      "Epoch: 8/100... Training loss: 0.1213\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1276\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1248\n",
      "Epoch: 8/100... Training loss: 0.1240\n",
      "Epoch: 8/100... Training loss: 0.1209\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1246\n",
      "Epoch: 8/100... Training loss: 0.1182\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1237\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1220\n",
      "Epoch: 8/100... Training loss: 0.1238\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1183\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1222\n",
      "Epoch: 8/100... Training loss: 0.1196\n",
      "Epoch: 8/100... Training loss: 0.1221\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1170\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1214\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1229\n",
      "Epoch: 8/100... Training loss: 0.1190\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1240\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1229\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1207\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1210\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1212\n",
      "Epoch: 8/100... Training loss: 0.1234\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1227\n",
      "Epoch: 8/100... Training loss: 0.1234\n",
      "Epoch: 8/100... Training loss: 0.1219\n",
      "Epoch: 8/100... Training loss: 0.1210\n",
      "Epoch: 8/100... Training loss: 0.1221\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1251\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1226\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1223\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1190\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1214\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1243\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1230\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1190\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1215\n",
      "Epoch: 8/100... Training loss: 0.1238\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1220\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1220\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1227\n",
      "Epoch: 8/100... Training loss: 0.1226\n",
      "Epoch: 8/100... Training loss: 0.1223\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1236\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1237\n",
      "Epoch: 8/100... Training loss: 0.1213\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1228\n",
      "Epoch: 8/100... Training loss: 0.1212\n",
      "Epoch: 8/100... Training loss: 0.1226\n",
      "Epoch: 8/100... Training loss: 0.1157\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1213\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1233\n",
      "Epoch: 8/100... Training loss: 0.1212\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1257\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1247\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1136\n",
      "Epoch: 8/100... Training loss: 0.1251\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1170\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1218\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1227\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1227\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1227\n",
      "Epoch: 8/100... Training loss: 0.1209\n",
      "Epoch: 8/100... Training loss: 0.1218\n",
      "Epoch: 8/100... Training loss: 0.1199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1227\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1209\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1190\n",
      "Epoch: 8/100... Training loss: 0.1196\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1206\n",
      "Epoch: 8/100... Training loss: 0.1152\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1219\n",
      "Epoch: 8/100... Training loss: 0.1230\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1221\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1219\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1221\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1224\n",
      "Epoch: 9/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1219\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1239\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1177\n",
      "Epoch: 9/100... Training loss: 0.1198\n",
      "Epoch: 9/100... Training loss: 0.1219\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1227\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1217\n",
      "Epoch: 9/100... Training loss: 0.1215\n",
      "Epoch: 9/100... Training loss: 0.1199\n",
      "Epoch: 9/100... Training loss: 0.1212\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1211\n",
      "Epoch: 9/100... Training loss: 0.1212\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1209\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1222\n",
      "Epoch: 9/100... Training loss: 0.1215\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1191\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1190\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1188\n",
      "Epoch: 9/100... Training loss: 0.1239\n",
      "Epoch: 9/100... Training loss: 0.1177\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1190\n",
      "Epoch: 9/100... Training loss: 0.1203\n",
      "Epoch: 9/100... Training loss: 0.1234\n",
      "Epoch: 9/100... Training loss: 0.1229\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1226\n",
      "Epoch: 9/100... Training loss: 0.1211\n",
      "Epoch: 9/100... Training loss: 0.1191\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1222\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1209\n",
      "Epoch: 9/100... Training loss: 0.1235\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1223\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1197\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1199\n",
      "Epoch: 9/100... Training loss: 0.1199\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1202\n",
      "Epoch: 9/100... Training loss: 0.1199\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1200\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1210\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1197\n",
      "Epoch: 9/100... Training loss: 0.1225\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1216\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1142\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1188\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1216\n",
      "Epoch: 9/100... Training loss: 0.1218\n",
      "Epoch: 9/100... Training loss: 0.1204\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1223\n",
      "Epoch: 9/100... Training loss: 0.1191\n",
      "Epoch: 9/100... Training loss: 0.1231\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1193\n",
      "Epoch: 9/100... Training loss: 0.1211\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1190\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1213\n",
      "Epoch: 9/100... Training loss: 0.1208\n",
      "Epoch: 9/100... Training loss: 0.1229\n",
      "Epoch: 9/100... Training loss: 0.1191\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1198\n",
      "Epoch: 9/100... Training loss: 0.1201\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1205\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1205\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1202\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1204\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1215\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1193\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1191\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1198\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100... Training loss: 0.1184\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1147\n",
      "Epoch: 9/100... Training loss: 0.1204\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1209\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1220\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1225\n",
      "Epoch: 9/100... Training loss: 0.1219\n",
      "Epoch: 9/100... Training loss: 0.1201\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1188\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1204\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1191\n",
      "Epoch: 9/100... Training loss: 0.1203\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1203\n",
      "Epoch: 9/100... Training loss: 0.1211\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1204\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1213\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1115\n",
      "Epoch: 9/100... Training loss: 0.1177\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1200\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1216\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1215\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1188\n",
      "Epoch: 9/100... Training loss: 0.1203\n",
      "Epoch: 9/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1211\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1190\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1203\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1207\n",
      "Epoch: 10/100... Training loss: 0.1133\n",
      "Epoch: 10/100... Training loss: 0.1220\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1205\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1197\n",
      "Epoch: 10/100... Training loss: 0.1187\n",
      "Epoch: 10/100... Training loss: 0.1207\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1202\n",
      "Epoch: 10/100... Training loss: 0.1185\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1175\n",
      "Epoch: 10/100... Training loss: 0.1180\n",
      "Epoch: 10/100... Training loss: 0.1175\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1185\n",
      "Epoch: 10/100... Training loss: 0.1219\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1198\n",
      "Epoch: 10/100... Training loss: 0.1190\n",
      "Epoch: 10/100... Training loss: 0.1180\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1212\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1190\n",
      "Epoch: 10/100... Training loss: 0.1186\n",
      "Epoch: 10/100... Training loss: 0.1202\n",
      "Epoch: 10/100... Training loss: 0.1184\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1207\n",
      "Epoch: 10/100... Training loss: 0.1191\n",
      "Epoch: 10/100... Training loss: 0.1192\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1133\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1223\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1221\n",
      "Epoch: 10/100... Training loss: 0.1107\n",
      "Epoch: 10/100... Training loss: 0.1190\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1162\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1199\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1197\n",
      "Epoch: 10/100... Training loss: 0.1172\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1186\n",
      "Epoch: 10/100... Training loss: 0.1219\n",
      "Epoch: 10/100... Training loss: 0.1175\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1187\n",
      "Epoch: 10/100... Training loss: 0.1162\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1204\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1187\n",
      "Epoch: 10/100... Training loss: 0.1198\n",
      "Epoch: 10/100... Training loss: 0.1181\n",
      "Epoch: 10/100... Training loss: 0.1202\n",
      "Epoch: 10/100... Training loss: 0.1181\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1162\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1200\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1197\n",
      "Epoch: 10/100... Training loss: 0.1161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100... Training loss: 0.1193\n",
      "Epoch: 10/100... Training loss: 0.1172\n",
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1199\n",
      "Epoch: 10/100... Training loss: 0.1175\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1180\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1216\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1206\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1220\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1177\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1177\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1188\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1172\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1192\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1184\n",
      "Epoch: 10/100... Training loss: 0.1186\n",
      "Epoch: 10/100... Training loss: 0.1204\n",
      "Epoch: 10/100... Training loss: 0.1180\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1190\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1185\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1188\n",
      "Epoch: 10/100... Training loss: 0.1181\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1185\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1172\n",
      "Epoch: 10/100... Training loss: 0.1175\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1184\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1187\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1133\n",
      "Epoch: 10/100... Training loss: 0.1185\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1162\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1186\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1196\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1196\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1210\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1130\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1109\n",
      "Epoch: 10/100... Training loss: 0.1175\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1202\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1116\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1180\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1172\n",
      "Epoch: 10/100... Training loss: 0.1196\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1184\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1174\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1106\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1209\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1220\n",
      "Epoch: 11/100... Training loss: 0.1168\n",
      "Epoch: 11/100... Training loss: 0.1209\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1186\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1159\n",
      "Epoch: 11/100... Training loss: 0.1143\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1174\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1171\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1169\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1151\n",
      "Epoch: 11/100... Training loss: 0.1186\n",
      "Epoch: 11/100... Training loss: 0.1178\n",
      "Epoch: 11/100... Training loss: 0.1106\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1181\n",
      "Epoch: 11/100... Training loss: 0.1197\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1103\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1182\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1220\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1188\n",
      "Epoch: 11/100... Training loss: 0.1129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1191\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1178\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1176\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1168\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1192\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1169\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1174\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1082\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1187\n",
      "Epoch: 11/100... Training loss: 0.1151\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1186\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1173\n",
      "Epoch: 11/100... Training loss: 0.1192\n",
      "Epoch: 11/100... Training loss: 0.1207\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1168\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1194\n",
      "Epoch: 11/100... Training loss: 0.1173\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1222\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1187\n",
      "Epoch: 11/100... Training loss: 0.1169\n",
      "Epoch: 11/100... Training loss: 0.1193\n",
      "Epoch: 11/100... Training loss: 0.1182\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1188\n",
      "Epoch: 11/100... Training loss: 0.1169\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1155\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1159\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1134\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1202\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1133\n",
      "Epoch: 11/100... Training loss: 0.1134\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1155\n",
      "Epoch: 11/100... Training loss: 0.1175\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1190\n",
      "Epoch: 11/100... Training loss: 0.1143\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1174\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1159\n",
      "Epoch: 11/100... Training loss: 0.1190\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1155\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1182\n",
      "Epoch: 11/100... Training loss: 0.1178\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1143\n",
      "Epoch: 11/100... Training loss: 0.1190\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1159\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1098\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1191\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1190\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1200\n",
      "Epoch: 11/100... Training loss: 0.1119\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1182\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1151\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1204\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1183\n",
      "Epoch: 11/100... Training loss: 0.1177\n",
      "Epoch: 11/100... Training loss: 0.1173\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1104\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1143\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1177\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1164\n",
      "Epoch: 11/100... Training loss: 0.1160\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1169\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1104\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1117\n"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "batch_size = 200\n",
    "with tf.Session() as sess:  \n",
    "    # Set's how much noise we're adding to the MNIST images\n",
    "    noise_factor = 0.5\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        for ii in range(mnist.train.num_examples//batch_size):\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            # Get images from the batch\n",
    "            imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        \n",
    "            # Add random noise to the input images\n",
    "            noisy_imgs = imgs + noise_factor * np.random.randn(*imgs.shape)\n",
    "            # Clip the images to be between 0 and 1\n",
    "            noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "        \n",
    "            # Noisy images as inputs, original images as targets\n",
    "            batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: noisy_imgs,\n",
    "                                                         targets_: imgs})\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.栈式自编码器\n",
    "(1)构建并训练栈式自编码\n",
    "(2)微调栈式自编码器\n",
    "(3)将栈式自编码器改进为栈式卷积自编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.使用TensorFlow构建与训练SAE模型，完成cifar10图像检索任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "cifar10 = input_data.read_data_sets(\"\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化权重函数\n",
    "def variable_with_weight_loss(shape,std,w1):\n",
    "    var = tf.Variable(tf.truncated_normal(shape,stddev=std),dtype=tf.float32)\n",
    "    if w1 is not None:\n",
    "        weight_loss = tf.multiply(tf.nn.l2_loss(var),w1,name=\"weight_loss\")\n",
    "        tf.add_to_collection(\"losses\",weight_loss)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取数据增强后的训练集数据\n",
    "images_train,labels_train = cifar10_input.distorted_inputs(cifar10_dir,batch_size)\n",
    "#获取数据裁剪后的测试数据\n",
    "images_test,labels_test = cifar10_input.inputs(eval_data=True,data_dir=cifar10_dir\n",
    "                                                   ,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设计第一层卷积\n",
    "    weight1 = variable_with_weight_loss(shape=[5,5,3,64],std=5e-2,w1=0)\n",
    "    kernel1 = tf.nn.conv2d(image_holder,weight1,[1,1,1,1],padding=\"SAME\")\n",
    "    bais1 = tf.Variable(tf.constant(0.0,dtype=tf.float32,shape=[64]))\n",
    "    conv1 = tf.nn.relu(tf.nn.bias_add(kernel1,bais1))\n",
    "    pool1 = tf.nn.max_pool(conv1,[1,3,3,1],[1,2,2,1],padding=\"SAME\")，\n",
    "    norm1 = tf.nn.lrn(pool1,4,bias=1.0,alpha=0.001 / 9,beta=0.75)\n",
    "#设计第二层卷积\n",
    "    weight2 = variable_with_weight_loss(shape=[5,5,64,64],std=5e-2,w1=0)\n",
    "    kernel2 = tf.nn.conv2d(norm1,weight2,[1,1,1,1],padding=\"SAME\")\n",
    "    bais2 = tf.Variable(tf.constant(0.1,dtype=tf.float32,shape=[64]))\n",
    "    conv2 = tf.nn.relu(tf.nn.bias_add(kernel2,bais2))\n",
    "    norm2 = tf.nn.lrn(conv2,4,bias=1.0,alpha=0.01 / 9,beta=0.75)\n",
    "    pool2 = tf.nn.max_pool(norm2,[1,3,3,1],[1,2,2,1],padding=\"SAME\")\n",
    " #第一层全连接层\n",
    "    reshape = tf.reshape(pool2,[batch_size,-1])\n",
    "    dim = reshape.get_shape()[1].value\n",
    "    weight3 = variable_with_weight_loss([dim,384],std=0.04,w1=0.004)\n",
    "    bais3 = tf.Variable(tf.constant(0.1,shape=[384],dtype=tf.float32))\n",
    "    local3 = tf.nn.relu(tf.matmul(reshape,weight3)+bais3)\n",
    "#第二层全连接层\n",
    "    weight4 = variable_with_weight_loss([384,192],std=0.04,w1=0.004)\n",
    "    bais4 = tf.Variable(tf.constant(0.1,shape=[192],dtype=tf.float32))\n",
    "    local4 = tf.nn.relu(tf.matmul(local3,weight4)+bais4)\n",
    " #最后一层\n",
    "    weight5 = variable_with_weight_loss([192,10],std=1/192.0,w1=0)\n",
    "    bais5 = tf.Variable(tf.constant(0.0,shape=[10],dtype=tf.float32))\n",
    "    logits = tf.add(tf.matmul(local4,weight5),bais5)\n",
    "\n",
    "#损失函数\n",
    "def loss_func(logits,labels):\n",
    "    labels = tf.cast(labels,tf.int32)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "                           labels=labels,name=\"cross_entropy_per_example\")\n",
    "    cross_entropy_mean = tf.reduce_mean(tf.reduce_sum(cross_entropy))\n",
    "    tf.add_to_collection(\"losses\",cross_entropy_mean)\n",
    "    return tf.add_n(tf.get_collection(\"losses\"),name=\"total_loss\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
